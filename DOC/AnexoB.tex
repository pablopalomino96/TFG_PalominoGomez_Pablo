\chapter{Tests del proyecto}
\label{cap:AnexoB}
Las pruebas o \textit{tests} son la etapa del ciclo de vida del software que consiste en la implementación de casos de prueba unitarios sobre cada una de las funcionalidades de una aplicación. Completar los tests con éxito en una aplicación implica:
\begin{itemize}
\item La aplicación es utilizable.
\item Se logra obtener el resultado esperado o definido para cada funcionalidad de la aplicación.
\item Existe control y manejo de errores.
\item La ejecución se realiza en un tiempo aceptable.
\item Los requisitos definidos durante el diseño y desarrollo han sido implementados correctamente.
\end{itemize}

Se ha utilizado el framework \textbf{Nose} para implementación de casos de prueba en Python. Se implementan tests que comprueban cada uno de los módulos que componen el sistema. En el directorio \textbf{test} se encuentran todos los ficheros relativos a las pruebas. (Véase el \textit{tree} del listado~\ref{lst:testree})
\begin{lstlisting}[numbers=none,caption={Estructura del directorio \textit{test}},label={lst:testree}]
 --- test
    |-- factories
    |   |
    |    -- factory_models.py
    |-- tests_api.py
    |-- tests_app.py
    |-- tests_models.py
\end{lstlisting}

La factoría de modelos (\textit{factory\_models}) se encarga de generar un usuario o hogar a petición de los tests, lo que agiliza muchísimo el proceso y fomenta la reutilización de código.\\

Los tests de API se encargan de comprobar la funcionalidad de las APIs empleadas en el sistema (Esios y AEMET). Las peticiones son probadas ejecutando las funciones de cada módulo y comprobando si el resultado obtenido es un buffer de 24 posiciones en caso de probar el éxito, o un buffer vacío en caso de probar el fallo.

Los tests de modelos comprueban la corrección de cada uno de los modelos \textit{User} y \textit{Home} realizando inserciones correctas, erróneas, borrados, y demás operaciones en la base de datos de test. Para ello se configura la aplicación en modo test mediante el fichero de configuración \textit{test\_config}.

El módulo de test \textit{tests\_app} tiene una gran importancia, pues contiene los casos de prueba unitarios referentes al \textit{routing} y vistas de la aplicación web. Para el primer tipo, se realizan casos de prueba cuyos \textit{asserts} comprueban los códigos http de retorno de cada una de las peticiones posibles a los \textit{endpoints} de la aplicación. Para el segundo tipo, los test de vistas, se comprueba si la información mostrada en la respuesta a una petición contiene lo esperado mediante \textit{assertIn}.

Cada módulo de test tiene dos funciones auxiliares \textit{setUp} y \textit{tearDown} cuyo objetivo es preparar la aplicación para efectuar los siguientes casos de prueba, y regenerar la base de datos de test y limpiar la basura generada en los tests.

Nose cuenta con una opción \textbf{--with-coverage} que permite comprobar la cobertura de código alcanzada en cada uno de los ficheros del proyecto. Esto es importante pues si existe una gran proporción de líneas de código probadas es mucho más dificil que un error inesperado ocurra. En la Tabla~\ref{tab:testcover} se muestra la cobertura alcanzada mediante la ejecución de los tests en el proyecto.
\begin{table}[hp]
        \centering
        \begin{tabular}{|l|c|}
                \hline
                \textbf{\textit{Fichero}} & \textbf{Cobertura de código} \\ \hline
                app.py & 85 \% \\ \hline
                models.py & 94 \% \\ \hline
                simulation.py & 99 \% \\ \hline
                config/prod\_config.py & 100 \% \\ \hline
                config/project\_constants.py & 100 \% \\ \hline
                helpers/api\_aemet.py & 98 \% \\ \hline
                helpers/api\_esios.py & 100 \% \\ \hline
             \end{tabular}
        \caption{Cobertura alcanzada en los tests del proyecto}
        \label{tab:testcover}
\end{table}
